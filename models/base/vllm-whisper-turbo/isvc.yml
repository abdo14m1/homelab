apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: whisper-turbo
spec:
  predictor:
    model:
      modelFormat:
        name: vllm
      runtime: whisper-vllm-runtime
    containers:
      - name: kserve-container
        volumeMounts:
          - name: model-volume
            mountPath: /mnt/models
            readOnly: true
    volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: whisper-model-pvc